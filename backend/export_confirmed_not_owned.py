"""ë¯¸ì†Œì¥ í™•ì • ë„ì„œ ëª©ë¡ ì¶”ì¶œ"""
import csv
from core.database import supabase

# 1. ì—¬ì „íˆ ë¯¸ì†Œì¥ì¸ 11ê¶Œ (ISBN ì—…ë°ì´íŠ¸í–ˆì§€ë§Œ ë¯¸ì†Œì¥)
still_not_owned_ids = []
with open('updated_books_loan_status.csv', 'r', encoding='utf-8-sig') as f:
    reader = csv.DictReader(f)
    for row in reader:
        if row['status'] == 'ë¯¸ì†Œì¥':
            still_not_owned_ids.append(int(row['id']))

print(f"ì—¬ì „íˆ ë¯¸ì†Œì¥: {len(still_not_owned_ids)}ê¶Œ")

# 2. ISBN ì—…ë°ì´íŠ¸ ì•ˆ ëœ ì±…ë“¤ (ë™ì¼í•˜ê±°ë‚˜ ëª» ì°¾ìŒ)
not_updated_ids = []
with open('not_owned_isbn_update.csv', 'r', encoding='utf-8-sig') as f:
    reader = csv.DictReader(f)
    for row in reader:
        if row['updated'] != 'True':
            not_updated_ids.append(int(row['id']))

print(f"ISBN ì—…ë°ì´íŠ¸ ì•ˆ ë¨: {len(not_updated_ids)}ê¶Œ")

# í•©ì¹˜ê¸°
all_ids = list(set(still_not_owned_ids + not_updated_ids))
print(f"ì´ ë¯¸ì†Œì¥ í™•ì •: {len(all_ids)}ê¶Œ")

# DBì—ì„œ ì¡°íšŒ
response = supabase.table("childbook_items")\
    .select("id, title, isbn, author, publisher, pangyo_callno")\
    .in_("id", all_ids)\
    .execute()

books = response.data

# CSV ì €ì¥
output_file = 'confirmed_not_owned_books.csv'
with open(output_file, 'w', newline='', encoding='utf-8-sig') as f:
    writer = csv.DictWriter(f, fieldnames=['title', 'isbn', 'author', 'publisher', 'pangyo_callno'])
    writer.writeheader()
    
    for book in books:
        writer.writerow({
            'title': book.get('title', ''),
            'isbn': book.get('isbn', ''),
            'author': book.get('author', ''),
            'publisher': book.get('publisher', ''),
            'pangyo_callno': book.get('pangyo_callno', '')
        })

print(f"\nâœ… CSV ì €ì¥ ì™„ë£Œ: {output_file}")
print(f"ğŸ“Š ì´ {len(books)}ê¶Œì˜ ë¯¸ì†Œì¥ í™•ì • ë„ì„œ")

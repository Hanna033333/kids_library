# -*- coding: utf-8 -*-
import json
import csv
import sys
import io

# Set encoding for console output
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

def main():
    print("ğŸ“‚ Loading data...")
    
    # 1. Load Original Targets
    with open('winter_books_clean.json', 'r', encoding='utf-8') as f:
        targets = json.load(f)
    print(f"  - Loaded {len(targets)} target books")

    # 2. Load Crawling Results
    results_map = {}
    try:
        with open('crawling_results.jsonl', 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    data = json.loads(line)
                    results_map[data['title']] = data
                except: pass
        print(f"  - Loaded {len(results_map)} crawling results")
    except FileNotFoundError:
        print("  - No crawling_results.jsonl found!")
        return

    # 3. Merge and Export
    output_file = 'winter_crawling_verification.csv'
    
    headers = ['ì—°ë²ˆ', 'ì„œëª…', 'ì €ì', 'ë°œí–‰ì', 'í¬ë¡¤ë§ ìƒíƒœ', 'ë§¤ì¹­ íƒ€ì…', 'ì²­êµ¬ê¸°í˜¸', 'ì—ëŸ¬ ë©”ì‹œì§€']
    
    with open(output_file, 'w', encoding='utf-8-sig', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(headers)
        
        for book in targets:
            title = book['ì„œëª…']
            result = results_map.get(title, {})
            
            row = [
                book.get('ì—°ë²ˆ', ''),
                title,
                book.get('ì €ì', ''),
                book.get('ë°œí–‰ì', ''),
                result.get('status', 'not_run'),
                result.get('match_type', '-'),
                result.get('callno', '-'),
                result.get('error', '-')
            ]
            writer.writerow(row)
            
    print(f"\nâœ… Export completed: {output_file}")

if __name__ == "__main__":
    main()

#!/usr/bin/env python
"""
ì¤‘ë³µëœ ì²­êµ¬ê¸°í˜¸ë¥¼ ê°€ì§„ ì±…ë“¤ì— ê¶Œì°¨ì •ë³´ ì¶”ê°€ (Refined Version 3)
- API ê²°ê³¼ì—ì„œ ISBN/ì œëª© ì—„ê²© ëŒ€ì¡° ë¡œì§ ì¶”ê°€
- itemSrch API í•„ìˆ˜ íŒŒë¼ë¯¸í„° ìœ ì§€
- 1ìˆœìœ„: ISBN ê¸°ë°˜ ê²€ìƒ‰
- 2ìˆœìœ„: ì œëª© ê¸°ë°˜ ê²€ìƒ‰ (ISBN ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ)
- ìºì‹±ì„ í†µí•´ ë™ì¼ ë„ì„œ ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€
"""

import asyncio
import aiohttp
import re
from typing import List, Dict, Optional, Set
from collections import defaultdict
from supabase_client import supabase
from core.config import DATA4LIBRARY_KEY

# íŒêµ ë„ì„œê´€ ì½”ë“œ
PANGYO_LIB_CODE = "141231"

# API ì •ë³´
ITEM_SRCH_URL = "http://data4library.kr/api/itemSrch"

def normalize_isbn(isbn: str) -> str:
    """ISBN ì •ê·œí™” (ìˆ«ìë§Œ ë‚¨ê¹€)"""
    if not isbn:
        return ""
    return re.sub(r"[^0-9]", "", isbn)

def normalize_title(title: str) -> str:
    """ì œëª© ì •ê·œí™” (ê³µë°±, ë¬¸ì¥ë¶€í˜¸ ì œê±°, ì†Œë¬¸ì ë³€í™˜)"""
    if not title:
        return ""
    # ê´„í˜¸ì™€ ê·¸ ì•ˆì˜ ë‚´ìš© ì œê±° (ì˜ˆ: (ê°œì •íŒ), [ì „ì§‘] ë“±)
    title = re.sub(r"\[.*?\]", "", title)
    title = re.sub(r"\(.*?\)", "", title)
    # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ê³µë°± ì œê±°
    title = re.sub(r"[^a-zA-Z0-9ê°€-í£]", "", title)
    return title.lower()

async def fetch_book_info_from_api(
    session: aiohttp.ClientSession, 
    isbn: Optional[str] = None, 
    title: Optional[str] = None
) -> List[Dict]:
    """ISBN ë˜ëŠ” ì œëª©ìœ¼ë¡œ API ê²€ìƒ‰ ìˆ˜í–‰"""
    results = []
    
    # 1. ISBN ê²€ìƒ‰ ì‹œë„
    if isbn:
        params = {
            "authKey": DATA4LIBRARY_KEY,
            "libCode": PANGYO_LIB_CODE,
            "type": "ISBN",
            "keyword": isbn,
            "startDt": "2000-01-01",
            "endDt": "2025-12-31",
            "pageNo": 1,
            "pageSize": 50, # ë„‰ë„‰í•˜ê²Œ ê°€ì ¸ì˜´
            "format": "json"
        }
        try:
            async with session.get(ITEM_SRCH_URL, params=params, timeout=30) as response:
                if response.status == 200:
                    data = await response.json()
                    docs = data.get("response", {}).get("docs", [])
                    for d in docs:
                        doc = d.get("doc", {})
                        api_isbn = normalize_isbn(doc.get("isbn13", ""))
                        if api_isbn == isbn: # ì—„ê²©í•œ ëŒ€ì¡°
                            results.append({
                                "isbn13": api_isbn,
                                "title": doc.get("bookname", ""),
                                "vol": doc.get("vol", "").strip(),
                                "normalized_title": normalize_title(doc.get("bookname", ""))
                            })
        except Exception as e:
            pass

    # 2. ì œëª© ê²€ìƒ‰ ì‹œë„ (ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ISBNì´ ì—†ëŠ” ê²½ìš°)
    if not results and title:
        params = {
            "authKey": DATA4LIBRARY_KEY,
            "libCode": PANGYO_LIB_CODE,
            "type": "TITLE",
            "keyword": title,
            "startDt": "2000-01-01",
            "endDt": "2025-12-31",
            "pageNo": 1,
            "pageSize": 100,
            "format": "json"
        }
        try:
            async with session.get(ITEM_SRCH_URL, params=params, timeout=30) as response:
                if response.status == 200:
                    data = await response.json()
                    docs = data.get("response", {}).get("docs", [])
                    norm_target_title = normalize_title(title)
                    for d in docs:
                        doc = d.get("doc", {})
                        api_title = doc.get("bookname", "")
                        api_norm_title = normalize_title(api_title)
                        # ì œëª©ì´ í¬í•¨ë˜ê±°ë‚˜ í¬í•¨í•˜ëŠ” ê²½ìš° ë§¤ì¹­
                        if norm_target_title in api_norm_title or api_norm_title in norm_target_title:
                            results.append({
                                "isbn13": normalize_isbn(doc.get("isbn13", "")),
                                "title": api_title,
                                "vol": doc.get("vol", "").strip(),
                                "normalized_title": api_norm_title
                            })
        except Exception as e:
            pass
            
    return results

def find_duplicate_callnos():
    """ì¤‘ë³µëœ ì²­êµ¬ê¸°í˜¸ë¥¼ ê°€ì§„ ì±…ë“¤ ì°¾ê¸°"""
    print("ğŸ” ì¤‘ë³µëœ ì²­êµ¬ê¸°í˜¸ ê²€ìƒ‰ ì¤‘...")
    response = supabase.table("childbook_items").select("id, isbn, title, pangyo_callno").execute()
    books = response.data
    
    callno_groups = defaultdict(list)
    for book in books:
        callno = book.get("pangyo_callno")
        if callno and callno.strip():
            callno_groups[callno].append(book)
    
    duplicates = {
        callno: books_list 
        for callno, books_list in callno_groups.items() 
        if len(books_list) > 1
    }
    
    print(f"âœ… {len(duplicates)}ê°œì˜ ì¤‘ë³µëœ ì²­êµ¬ê¸°í˜¸ ë°œê²¬")
    return duplicates

async def add_volume_info_refined():
    log_file = open("volume_update_log_v3.txt", "w", encoding="utf-8")
    def log(msg):
        print(msg, flush=True)
        log_file.write(msg + "\n")
        log_file.flush()
        
    log("\n" + "="*60)
    log("ğŸ“š ì¤‘ë³µ ì²­êµ¬ê¸°í˜¸ ì±…ë“¤ì— ê¶Œì°¨ì •ë³´ ì¶”ê°€ (ISBN/Title Refined V3)")
    log("="*60 + "\n")
    
    duplicates = find_duplicate_callnos()
    if not duplicates:
        log("âœ… ì¤‘ë³µëœ ì²­êµ¬ê¸°í˜¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        log_file.close()
        return
    
    total_books_sum = sum(len(v) for v in duplicates.values())
    log(f"\nğŸ“Š ì´ {len(duplicates)}ê°œ ê·¸ë£¹, {total_books_sum}ê¶Œì˜ ë„ì„œ ì²˜ë¦¬ ì˜ˆì •\n")
    
    updated_count = 0
    matched_by_isbn = 0
    matched_by_title_exact = 0
    matched_by_title_partial = 0
    failed_count = 0
    
    # ìºì‹œ (ISBN -> API ê²°ê³¼)
    isbn_cache = {}
    # ìºì‹œ (ì •ê·œí™”ëœ ì œëª© -> API ê²°ê³¼)
    title_cache = {}
    
    async with aiohttp.ClientSession() as session:
        for idx, (callno, books_list) in enumerate(duplicates.items(), 1):
            log(f"\n[{idx}/{len(duplicates)}] ğŸ“‚ ì²­êµ¬ê¸°í˜¸: {callno} ({len(books_list)}ê¶Œ)")
            
            for book in books_list:
                db_id = book["id"]
                db_isbn = normalize_isbn(book.get("isbn") or "")
                db_title = book.get("title") or ""
                db_norm_title = normalize_title(db_title)
                
                log(f"  ğŸ“– ì²˜ë¦¬ ì¤‘: {db_title[:20]}... (ISBN: {db_isbn})")
                
                api_results = []
                # 1. ISBNìœ¼ë¡œ ìºì‹œ í™•ì¸ ë˜ëŠ” API í˜¸ì¶œ
                if db_isbn:
                    if db_isbn in isbn_cache:
                        api_results = isbn_cache[db_isbn]
                    else:
                        api_results = await fetch_book_info_from_api(session, isbn=db_isbn)
                        isbn_cache[db_isbn] = api_results
                        await asyncio.sleep(0.3)
                
                # 2. ISBN ê²°ê³¼ê°€ ì—†ê³  ì œëª©ì´ ìˆìœ¼ë©´ ì œëª©ìœ¼ë¡œ ìºì‹œ í™•ì¸ ë˜ëŠ” API í˜¸ì¶œ
                if not api_results and db_norm_title:
                    if db_norm_title in title_cache:
                        api_results = title_cache[db_norm_title]
                    else:
                        api_results = await fetch_book_info_from_api(session, title=db_title)
                        title_cache[db_norm_title] = api_results
                        await asyncio.sleep(0.3)
                
                matched_vol = None
                match_method = ""
                
                if api_results:
                    # 1. ISBN ë§¤ì¹­ ì‹œë„
                    if db_isbn:
                        for res in api_results:
                            if res["isbn13"] == db_isbn and res["vol"]:
                                matched_vol = res["vol"]
                                match_method = "ISBN"
                                break
                    
                    # 2. ì œëª© ì •í™• ë§¤ì¹­ ì‹œë„
                    if not matched_vol:
                        for res in api_results:
                            if res["normalized_title"] == db_norm_title and res["vol"]:
                                matched_vol = res["vol"]
                                match_method = "Title_Exact"
                                break
                    
                    # 3. ì œëª© ë¶€ë¶„ ë§¤ì¹­ ì‹œë„
                    if not matched_vol and len(db_norm_title) >= 3:
                        for res in api_results:
                            api_norm_title = res["normalized_title"]
                            if api_norm_title and (db_norm_title in api_norm_title or api_norm_title in db_norm_title):
                                if res["vol"]:
                                    matched_vol = res["vol"]
                                    match_method = "Title_Partial"
                                    break
                
                if matched_vol:
                    try:
                        supabase.table("childbook_items").update({"vol": matched_vol}).eq("id", db_id).execute()
                        log(f"    âœ… [{match_method}] ë§¤ì¹­ ì„±ê³µ! vol: '{matched_vol}'")
                        updated_count += 1
                        if match_method == "ISBN": matched_by_isbn += 1
                        elif match_method == "Title_Exact": matched_by_title_exact += 1
                        else: matched_by_title_partial += 1
                    except Exception as e:
                        log(f"    âŒ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                        failed_count += 1
                else:
                    log(f"    âš ï¸ ë§¤ì¹­ ì‹¤íŒ¨")
                    failed_count += 1

    log(f"\n" + "="*60)
    log(f"âœ… ì´ {updated_count}ê¶Œ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
    log(f"   - ISBN ë§¤ì¹­: {matched_by_isbn}")
    log(f"   - ì œëª© ì •í™• ë§¤ì¹­: {matched_by_title_exact}")
    log(f"   - ì œëª© ë¶€ë¶„ ë§¤ì¹­: {matched_by_title_partial}")
    log(f"âŒ ë§¤ì¹­ ì‹¤íŒ¨: {failed_count}ê¶Œ")
    log("="*60)
    log_file.close()

if __name__ == "__main__":
    asyncio.run(add_volume_info_refined())
